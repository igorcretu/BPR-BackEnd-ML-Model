{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95734c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Database Configuration\n",
    "DB_NAME = os.getenv(\"DB_NAME\", \"bpr_cars\")\n",
    "DB_USER = os.getenv(\"DB_USER\", \"postgres\")\n",
    "DB_PASS = os.getenv(\"DB_PASS\", \"postgres\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\", \"localhost\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\", \"5432\")\n",
    "\n",
    "TABLE_NAME = 'cars'\n",
    "CSV_FILE = 'bilbasen_scrape/car_details.csv'\n",
    "\n",
    "print(f\"üìä Database: {DB_NAME}@{DB_HOST}:{DB_PORT}\")\n",
    "print(f\"üìÅ CSV File: {CSV_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419cde97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV Data\n",
    "df = pd.read_csv(CSV_FILE, low_memory=False)\n",
    "print(f\"‚úÖ Loaded {len(df)} rows from {CSV_FILE}\")\n",
    "print(f\"\\nColumns in CSV ({len(df.columns)}):\")\n",
    "print(list(df.columns))\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da28f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data types and missing values\n",
    "print(\"\\nüìä Data Quality Report:\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"\\nMissing values per column:\")\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "missing_report = pd.DataFrame({'Missing': missing, 'Percent': missing_pct})\n",
    "print(missing_report[missing_report['Missing'] > 0].sort_values('Missing', ascending=False))\n",
    "\n",
    "print(f\"\\nüîë External ID analysis:\")\n",
    "print(f\"Unique external_ids: {df['external_id'].nunique()}\")\n",
    "print(f\"Duplicate external_ids: {df['external_id'].duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cb938f",
   "metadata": {},
   "source": [
    "## Helper Functions for Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f31118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_price(price_str):\n",
    "    \"\"\"Extract numeric price from strings like '38.900 kr.' or '250.000 kr.'\"\"\"\n",
    "    if pd.isna(price_str):\n",
    "        return None\n",
    "    # Remove 'kr.', spaces, and dots, then convert to float\n",
    "    cleaned = str(price_str).replace('kr.', '').replace('.', '').replace(',', '.').strip()\n",
    "    try:\n",
    "        return float(cleaned)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def clean_numeric(value, allow_comma=False):\n",
    "    \"\"\"Clean numeric values, handle commas as decimal separators\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    cleaned = str(value).replace('.', '').replace(',', '.').strip()\n",
    "    try:\n",
    "        return float(cleaned)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_horsepower(power_str):\n",
    "    \"\"\"Extract HP from strings like '60 HK / 44 kW' or '150 HK'\"\"\"\n",
    "    if pd.isna(power_str):\n",
    "        return None\n",
    "    match = re.search(r'(\\d+)\\s*HK', str(power_str))\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "def extract_torque(power_str):\n",
    "    \"\"\"Extract Nm from strings like '60 HK / 44 kW / 120 Nm'\"\"\"\n",
    "    if pd.isna(power_str):\n",
    "        return None\n",
    "    match = re.search(r'(\\d+)\\s*Nm', str(power_str))\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return None\n",
    "\n",
    "def extract_mileage(mileage_str):\n",
    "    \"\"\"Extract mileage from strings like '150.000 km' or use mileage_km_numeric\"\"\"\n",
    "    if pd.isna(mileage_str):\n",
    "        return None\n",
    "    # Remove 'km', spaces, dots\n",
    "    cleaned = str(mileage_str).replace('km', '').replace('.', '').replace(',', '').strip()\n",
    "    try:\n",
    "        return int(cleaned)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_date(date_str):\n",
    "    \"\"\"Parse dates in various formats\"\"\"\n",
    "    if pd.isna(date_str) or date_str == '':\n",
    "        return None\n",
    "    try:\n",
    "        # Try ISO format first\n",
    "        return pd.to_datetime(date_str).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def parse_boolean(value):\n",
    "    \"\"\"Parse boolean values from various formats\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    if str(value).lower() in ['true', 'yes', 'ja', '1', 't', 'y']:\n",
    "        return True\n",
    "    if str(value).lower() in ['false', 'no', 'nej', '0', 'f', 'n']:\n",
    "        return False\n",
    "    return None\n",
    "\n",
    "def extract_co2(co2_str):\n",
    "    \"\"\"Extract CO2 value from strings like '120 g/km'\"\"\"\n",
    "    if pd.isna(co2_str):\n",
    "        return None\n",
    "    match = re.search(r'(\\d+)', str(co2_str))\n",
    "    if match:\n",
    "        return str(match.group(1)) + ' g/km'\n",
    "    return str(co2_str)\n",
    "\n",
    "# Test the functions\n",
    "print(\"Testing helper functions:\")\n",
    "print(f\"Price '38.900 kr.' -> {clean_price('38.900 kr.')}\")\n",
    "print(f\"Price '250.000 kr.' -> {clean_price('250.000 kr.')}\")\n",
    "print(f\"Horsepower '150 HK / 110 kW' -> {extract_horsepower('150 HK / 110 kW')}\")\n",
    "print(f\"Mileage '150.000 km' -> {extract_mileage('150.000 km')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fb507c",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a7afc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a clean DataFrame for upload\n",
    "clean_df = pd.DataFrame()\n",
    "\n",
    "# Generate UUIDs and external_id\n",
    "clean_df['id'] = [str(uuid.uuid4()) for _ in range(len(df))]\n",
    "clean_df['external_id'] = df['external_id'].astype(str)\n",
    "\n",
    "# Basic info\n",
    "clean_df['url'] = df['url']\n",
    "clean_df['brand'] = df['brand']\n",
    "clean_df['model'] = df['model']\n",
    "clean_df['variant'] = df['variant']\n",
    "clean_df['title'] = df['title']\n",
    "clean_df['description'] = df['description']\n",
    "\n",
    "# Price\n",
    "clean_df['price'] = df['price'].apply(clean_price)\n",
    "clean_df['new_price'] = df['model_new_price'].apply(clean_price)\n",
    "\n",
    "# Years and dates\n",
    "clean_df['model_year'] = pd.to_numeric(df['details_model_year'], errors='coerce').astype('Int64')\n",
    "clean_df['year'] = clean_df['model_year']  # Use model_year as primary year\n",
    "clean_df['first_registration'] = df['details_first_registration']\n",
    "clean_df['production_date'] = df['details_production_year']\n",
    "\n",
    "# Mileage - prefer mileage_km_numeric if available\n",
    "clean_df['mileage'] = df['mileage_km_numeric'].fillna(df['details_mileage_km'].apply(extract_mileage))\n",
    "clean_df['mileage'] = pd.to_numeric(clean_df['mileage'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Fuel and transmission\n",
    "clean_df['fuel_type'] = df['details_fuel_type']\n",
    "clean_df['transmission'] = df['details_geartype'].fillna(df['attr_gear_type'])\n",
    "clean_df['gear_count'] = pd.to_numeric(df['details_number_of_gears'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Engine specs\n",
    "clean_df['cylinders'] = pd.to_numeric(df['model_cylinders'], errors='coerce').astype('Int64')\n",
    "clean_df['horsepower'] = df['details_power_hp_nm'].apply(extract_horsepower).fillna(\n",
    "    pd.to_numeric(df['attr_power_hp'], errors='coerce')\n",
    ").astype('Int64')\n",
    "clean_df['torque_nm'] = df['details_power_hp_nm'].apply(extract_torque).astype('Int64')\n",
    "\n",
    "# Performance\n",
    "clean_df['acceleration'] = df['details_acceleration_0_100'].apply(clean_numeric).fillna(\n",
    "    df['attr_acceleration_0_100'].apply(clean_numeric)\n",
    ")\n",
    "clean_df['top_speed'] = pd.to_numeric(df['details_top_speed'], errors='coerce').fillna(\n",
    "    pd.to_numeric(df['attr_top_speed_kmh'], errors='coerce')\n",
    ").astype('Int64')\n",
    "\n",
    "# Electric vehicle specs\n",
    "clean_df['range_km'] = pd.to_numeric(df['details_range_km'], errors='coerce').astype('Int64')\n",
    "clean_df['battery_capacity'] = df['details_battery_capacity_kwh'].apply(clean_numeric)\n",
    "clean_df['energy_consumption'] = pd.to_numeric(df['details_energy_consumption'], errors='coerce').astype('Int64')\n",
    "clean_df['home_charging_ac'] = df['details_home_charging_ac']\n",
    "clean_df['fast_charging_dc'] = df['details_fast_charging_dc']\n",
    "clean_df['charging_time_dc'] = df['details_charging_time_dc_10_80_pct']\n",
    "\n",
    "# Fuel consumption and emissions\n",
    "clean_df['fuel_consumption'] = df['details_fuel_consumption']\n",
    "clean_df['co2_emission'] = df['details_co2_udledning'].apply(extract_co2)\n",
    "clean_df['euro_norm'] = df['details_euro_norm']\n",
    "clean_df['tank_capacity'] = pd.to_numeric(df['model_tankkapacitet'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Physical specs\n",
    "clean_df['body_type'] = df['model_body_type']\n",
    "clean_df['weight'] = pd.to_numeric(df['model_weight_kg'], errors='coerce').fillna(\n",
    "    pd.to_numeric(df['attr_weight_kg'], errors='coerce')\n",
    ").astype('Int64')\n",
    "clean_df['width'] = pd.to_numeric(df['model_width_cm'], errors='coerce').astype('Int64')\n",
    "clean_df['length'] = pd.to_numeric(df['model_length_cm'], errors='coerce').astype('Int64')\n",
    "clean_df['height'] = pd.to_numeric(df['model_height_cm'], errors='coerce').astype('Int64')\n",
    "clean_df['trunk_size'] = pd.to_numeric(df['model_trunk_size'], errors='coerce').astype('Int64')\n",
    "clean_df['load_capacity'] = pd.to_numeric(df['model_load_capacity_kg'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Towing\n",
    "clean_df['towing_capacity'] = df['details_towing_capacity'].apply(clean_numeric).astype('Int64')\n",
    "clean_df['max_towing_weight'] = pd.to_numeric(df['model_max_towing_with_brake'], errors='coerce').astype('Int64')\n",
    "\n",
    "# Drive and safety\n",
    "clean_df['drive_type'] = df['model_drive_type']\n",
    "clean_df['abs_brakes'] = df['model_abs_brakes'].apply(parse_boolean)\n",
    "clean_df['esp'] = df['model_esp'].apply(parse_boolean)\n",
    "clean_df['airbags'] = pd.to_numeric(df['model_airbags'], errors='coerce').astype('Int64')\n",
    "clean_df['doors'] = pd.to_numeric(df['model_doors'], errors='coerce').astype('Int64')\n",
    "clean_df['seats'] = None  # Not in scraper output\n",
    "\n",
    "# Color and category\n",
    "clean_df['color'] = df['details_color'].fillna(df['attr_color'])\n",
    "clean_df['category'] = df['model_category']\n",
    "clean_df['equipment'] = df['equipment']\n",
    "\n",
    "# Tax\n",
    "clean_df['periodic_tax'] = df['details_periodic_tax']\n",
    "clean_df['tax'] = df['details_periodic_tax'].apply(clean_price)  # NEW: Store tax as numeric\n",
    "\n",
    "# Engine size (not in scraper, set to None)\n",
    "clean_df['engine_size'] = None\n",
    "\n",
    "# Location and seller\n",
    "clean_df['source_url'] = df['url']\n",
    "clean_df['location'] = df['seller_city'].fillna('') + ' ' + df['seller_zipcode'].fillna('')\n",
    "clean_df['location'] = clean_df['location'].str.strip()\n",
    "clean_df['dealer_name'] = df['seller_name']\n",
    "\n",
    "# Image handling - NEW\n",
    "clean_df['image_path'] = df['image_filename'].apply(\n",
    "    lambda x: f\"bilbasen_scrape/images/{x}\" if pd.notna(x) and x != '' else None\n",
    ")\n",
    "clean_df['image_downloaded'] = False  # Will be updated by auto_scraper\n",
    "\n",
    "# Timestamps\n",
    "clean_df['listing_date'] = df['listing_date'].apply(parse_date)\n",
    "clean_df['created_at'] = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
    "clean_df['updated_at'] = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(f\"\\n‚úÖ Cleaned data ready: {len(clean_df)} rows, {len(clean_df.columns)} columns\")\n",
    "print(f\"\\nColumns in clean DataFrame:\")\n",
    "print(list(clean_df.columns))\n",
    "clean_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe44758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for required fields\n",
    "print(\"\\nüîç Required fields validation:\")\n",
    "required = ['external_id', 'brand', 'model', 'price']\n",
    "for col in required:\n",
    "    missing = clean_df[col].isna().sum()\n",
    "    print(f\"{col}: {missing} missing ({missing/len(clean_df)*100:.2f}%)\")\n",
    "\n",
    "# Drop rows with missing required fields\n",
    "before_count = len(clean_df)\n",
    "clean_df = clean_df.dropna(subset=['external_id', 'brand', 'model', 'price'])\n",
    "after_count = len(clean_df)\n",
    "print(f\"\\n‚úÇÔ∏è Dropped {before_count - after_count} rows with missing required fields\")\n",
    "print(f\"Final dataset: {after_count} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaab17f",
   "metadata": {},
   "source": [
    "## Upload to Database with UPSERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07480341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "try:\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=DB_NAME,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASS,\n",
    "        host=DB_HOST,\n",
    "        port=DB_PORT\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "    print(f\"‚úÖ Connected to database: {DB_NAME}\")\n",
    "    \n",
    "    # Check current count\n",
    "    cur.execute(f\"SELECT COUNT(*) FROM {TABLE_NAME}\")\n",
    "    before_count = cur.fetchone()[0]\n",
    "    print(f\"üìä Current rows in {TABLE_NAME}: {before_count}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Database connection failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5f8951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for UPSERT\n",
    "# Replace None with NULL for psycopg2\n",
    "upload_data = clean_df.where(pd.notnull(clean_df), None)\n",
    "\n",
    "# Convert to list of tuples\n",
    "data_tuples = [tuple(x) for x in upload_data.values]\n",
    "\n",
    "print(f\"\\nüì¶ Prepared {len(data_tuples)} records for upload\")\n",
    "print(f\"Sample record (first 10 fields): {data_tuples[0][:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d817fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build UPSERT query\n",
    "columns = list(clean_df.columns)\n",
    "columns_str = ', '.join(columns)\n",
    "placeholders = ', '.join(['%s'] * len(columns))\n",
    "\n",
    "# Update columns (all except id and external_id)\n",
    "update_columns = [col for col in columns if col not in ['id', 'external_id']]\n",
    "update_str = ', '.join([f\"{col} = EXCLUDED.{col}\" for col in update_columns])\n",
    "\n",
    "upsert_query = f\"\"\"\n",
    "    INSERT INTO {TABLE_NAME} ({columns_str})\n",
    "    VALUES %s\n",
    "    ON CONFLICT (external_id)\n",
    "    DO UPDATE SET {update_str}\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüìù UPSERT Query prepared (will insert new or update existing based on external_id)\")\n",
    "print(f\"Columns: {len(columns)}\")\n",
    "print(f\"Update fields: {len(update_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c5323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute UPSERT in batches\n",
    "batch_size = 1000\n",
    "total_batches = (len(data_tuples) + batch_size - 1) // batch_size\n",
    "\n",
    "print(f\"\\nüöÄ Starting upload in {total_batches} batches of {batch_size}...\")\n",
    "\n",
    "try:\n",
    "    for i in range(0, len(data_tuples), batch_size):\n",
    "        batch = data_tuples[i:i+batch_size]\n",
    "        execute_values(cur, upsert_query, batch, page_size=100)\n",
    "        batch_num = i // batch_size + 1\n",
    "        print(f\"‚úÖ Batch {batch_num}/{total_batches} uploaded ({len(batch)} records)\")\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"\\n‚úÖ All data committed to database!\")\n",
    "    \n",
    "    # Check final count\n",
    "    cur.execute(f\"SELECT COUNT(*) FROM {TABLE_NAME}\")\n",
    "    after_count = cur.fetchone()[0]\n",
    "    \n",
    "    print(f\"\\nüìä Upload Summary:\")\n",
    "    print(f\"Before: {before_count} rows\")\n",
    "    print(f\"After: {after_count} rows\")\n",
    "    print(f\"Net change: +{after_count - before_count} rows\")\n",
    "    \n",
    "except Exception as e:\n",
    "    conn.rollback()\n",
    "    print(f\"\\n‚ùå Upload failed: {e}\")\n",
    "    raise\n",
    "finally:\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    print(f\"\\nüîí Database connection closed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b07cb23",
   "metadata": {},
   "source": [
    "## Verify Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d6285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconnect and verify\n",
    "conn = psycopg2.connect(\n",
    "    dbname=DB_NAME,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASS,\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT\n",
    ")\n",
    "\n",
    "# Sample queries\n",
    "queries = [\n",
    "    (\"Total cars\", \"SELECT COUNT(*) FROM cars\"),\n",
    "    (\"Cars with external_id\", \"SELECT COUNT(*) FROM cars WHERE external_id IS NOT NULL\"),\n",
    "    (\"Cars with images\", \"SELECT COUNT(*) FROM cars WHERE image_path IS NOT NULL\"),\n",
    "    (\"Highest external_id\", \"SELECT MAX(external_id::bigint) FROM cars\"),\n",
    "    (\"Brands\", \"SELECT COUNT(DISTINCT brand) FROM cars\"),\n",
    "    (\"Fuel types\", \"SELECT fuel_type, COUNT(*) FROM cars GROUP BY fuel_type ORDER BY COUNT(*) DESC LIMIT 5\")\n",
    "]\n",
    "\n",
    "print(\"\\nüîç Database Verification:\\n\")\n",
    "for description, query in queries:\n",
    "    result = pd.read_sql(query, conn)\n",
    "    print(f\"{description}:\")\n",
    "    print(result)\n",
    "    print()\n",
    "\n",
    "conn.close()\n",
    "print(\"‚úÖ Verification complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
